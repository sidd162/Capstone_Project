{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Master_Copy_of_Application_of_SP_Colab_ngrok_Abhilash_Jash.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pZBI-8J4Y6yR",
        "outputId": "c00c536c-3ef3-49c8-e6a2-56037fd8c112"
      },
      "source": [
        "!pip install streamlit\n",
        "!pip install yfinance\n",
        "#!pip install pyngrok #Gives Error\n",
        "!pip install pyngrok==4.1.1\n",
        "!pip install PyPortfolioOpt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/11/57097e14f72a2d1b2a1bbe86c2a8bc375661bfd5c30b5e8cee7c2fad9a44/streamlit-0.82.0-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 4.2MB/s \n",
            "\u001b[?25hCollecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/bc/f0e44828e4290367c869591d50d3671a4d0ee94926da6cb734b7b200308c/pydeck-0.6.2-py2.py3-none-any.whl (4.2MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2MB 30.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/a1/d9f565e9910c09fd325dc638765e8843a19fa696275c16cc08cf3b0a3c25/base58-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Collecting watchdog; platform_system != \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/5b/36b3b11e557830de6fc1dc06e9aa3ee274119b8cea9cc98175dbbf72cf87/watchdog-2.1.2-py3-none-manylinux2014_x86_64.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.7MB/s \n",
            "\u001b[?25hCollecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 37.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.1)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Collecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 36.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Collecting click<8.0,>=7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.12.4)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (2.11.3)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/6d/6c8fe4b658f77947d4244ce81f60230c4c8d1dc1a21ae83e63b269339178/ipykernel-5.5.5-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (1.15.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (4.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from gitpython->streamlit) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tzlocal->streamlit) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (56.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10.1->pydeck>=0.1.dev5->streamlit) (2.0.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (22.0.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.5)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Building wheels for collected packages: blinker\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp37-none-any.whl size=13448 sha256=e5cb958adc739ba547297e0722499ca1aa8918a65512e2c8492a8164400e7e97\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "Successfully built blinker\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ipykernel, pydeck, base58, watchdog, validators, smmap, gitdb, gitpython, blinker, click, streamlit\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "  Found existing installation: click 8.0.0\n",
            "    Uninstalling click-8.0.0:\n",
            "      Successfully uninstalled click-8.0.0\n",
            "Successfully installed base58-2.1.0 blinker-1.4 click-7.1.2 gitdb-4.0.7 gitpython-3.1.17 ipykernel-5.5.5 pydeck-0.6.2 smmap-4.0.0 streamlit-0.82.0 validators-0.18.2 watchdog-2.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/ee/315752b9ef281ba83c62aa7ec2e2074f85223da6e7e74efb4d3e11c0f510/yfinance-0.1.59.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/c0/d0526314971fc661b083ab135747dc68446a3022686da8c16d25fcf6ef07/lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3MB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.59-py2.py3-none-any.whl size=23442 sha256=4dc9d6139ebcaf8b5fc6ee524b4ad012682209966e49e1c6d9405c6409091be9\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/2a/0f/4b5a86e1d52e451757eb6bc17fd899629f0925c777741b6d04\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.3 yfinance-0.1.59\n",
            "Collecting pyngrok==4.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/a9/de2e15c92eb3aa4a2646ce3a7542317eb69ac47f667578ce8bf916320847/pyngrok-4.1.1.tar.gz\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (0.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-cp37-none-any.whl size=15971 sha256=7dd51fcc0d5fad0ce91ebe375cd78c151673bfee73f6fba64d18a2e70b7bbb0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/71/0d/1695f7c8815c0beb3b5d9b35d6eec9243c87e6070fbe3977fa\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n",
            "Collecting PyPortfolioOpt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/55/7d39d78d554ee33a7317e345caf01339da11406c28f18bc48794fe967935/PyPortfolioOpt-1.4.1-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.19.5)\n",
            "Collecting cvxpy<2.0.0,>=1.1.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/47/fd1e818b8da30ef18695a0fbf9b66611ab18506f0a44fc69480a75f4db1b/cvxpy-1.1.12.tar.gz (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 6.8MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.1.5)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (0.6.2.post0)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (2.1.3)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (2.0.7.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2018.9)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (0.1.5.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19->PyPortfolioOpt) (1.15.0)\n",
            "Building wheels for collected packages: cvxpy\n",
            "  Building wheel for cvxpy (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cvxpy: filename=cvxpy-1.1.12-cp37-cp37m-linux_x86_64.whl size=2731595 sha256=af7c97d05c2e0c220cac41f9135aca6c84399842bdf63d58d19c6e9f78bb52f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/62/55/1da181c05c710c5d99bd560edebec3bd6a61cb69acef9dc00e\n",
            "Successfully built cvxpy\n",
            "Installing collected packages: cvxpy, PyPortfolioOpt\n",
            "  Found existing installation: cvxpy 1.0.31\n",
            "    Uninstalling cvxpy-1.0.31:\n",
            "      Successfully uninstalled cvxpy-1.0.31\n",
            "Successfully installed PyPortfolioOpt-1.4.1 cvxpy-1.1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUQQPUnTDIZI",
        "outputId": "3864949e-5a43-4895-9121-22cb7ca6e14d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbX-A4NSZDkZ"
      },
      "source": [
        "#You may upload the nipty50 dataset from here. Or Load it from Google drive as I have done.\n",
        "#Uncomment and upload file.\n",
        "from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4NuRoaJ-ZUea",
        "outputId": "40046be9-9bb1-41fa-d865-c98162c23640"
      },
      "source": [
        "#Storing in a dataframe\n",
        "import pandas as pd\n",
        "nifty50 = pd.read_excel(\"/content/drive/MyDrive/Datasets/NIFTY50.xlsx\")\n",
        "nifty50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adani Ports</th>\n",
              "      <th>ADANIPORTS.NS</th>\n",
              "      <th>Infrastructure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Asian Paints</td>\n",
              "      <td>ASIANPAINT.NS</td>\n",
              "      <td>Consumer Goods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Axis Bank</td>\n",
              "      <td>AXISBANK.NS</td>\n",
              "      <td>Banking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bajaj Auto</td>\n",
              "      <td>BAJAJ-AUTO.NS</td>\n",
              "      <td>Automobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bajaj Finance</td>\n",
              "      <td>BAJFINANCE.NS</td>\n",
              "      <td>Financial Services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bajaj Finserv</td>\n",
              "      <td>BAJAJFINSV.NS</td>\n",
              "      <td>Financial Services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bharti Airtel</td>\n",
              "      <td>BHARTIARTL.NS</td>\n",
              "      <td>Telecommunication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bharat Petroleum</td>\n",
              "      <td>BPCL.NS</td>\n",
              "      <td>Energy - Oil &amp; Gas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Britannia Industries</td>\n",
              "      <td>BRITANNIA.NS</td>\n",
              "      <td>Consumer Goods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Cipla</td>\n",
              "      <td>CIPLA.NS</td>\n",
              "      <td>Pharmaceuticals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Coal India</td>\n",
              "      <td>COALINDIA.NS</td>\n",
              "      <td>Energy &amp; Mining</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Divi's Laboratories</td>\n",
              "      <td>DIVISLAB.NS</td>\n",
              "      <td>Pharmaceuticals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Dr. Reddy's Laboratories</td>\n",
              "      <td>DRREDDY.NS</td>\n",
              "      <td>Pharmaceuticals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Eicher Motors</td>\n",
              "      <td>EICHERMOT.NS</td>\n",
              "      <td>Automobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Grasim Industries</td>\n",
              "      <td>GRASIM.NS</td>\n",
              "      <td>Cement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>HCL Technologies</td>\n",
              "      <td>HCLTECH.NS</td>\n",
              "      <td>Information Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>HDFC</td>\n",
              "      <td>HDFC.NS</td>\n",
              "      <td>Financial Services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>HDFC Bank</td>\n",
              "      <td>HDFCBANK.NS</td>\n",
              "      <td>Banking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>HDFC Life</td>\n",
              "      <td>HDFCLIFE.NS</td>\n",
              "      <td>Insurance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Hero MotoCorp</td>\n",
              "      <td>HEROMOTOCO.NS</td>\n",
              "      <td>Automobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Hindalco Industries</td>\n",
              "      <td>HINDALCO.NS</td>\n",
              "      <td>Metals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Hindustan Unilever</td>\n",
              "      <td>HINDUNILVR.NS</td>\n",
              "      <td>Consumer Goods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>ICICI Bank</td>\n",
              "      <td>ICICIBANK.NS</td>\n",
              "      <td>Banking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>IndusInd Bank</td>\n",
              "      <td>INDUSINDBK.NS</td>\n",
              "      <td>Banking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Infosys</td>\n",
              "      <td>INFY.NS</td>\n",
              "      <td>Information Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Indian Oil Corporation</td>\n",
              "      <td>IOC.NS</td>\n",
              "      <td>Energy - Oil &amp; Gas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>ITC Limited</td>\n",
              "      <td>ITC.NS</td>\n",
              "      <td>Consumer Goods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>JSW Steel</td>\n",
              "      <td>JSWSTEEL.NS</td>\n",
              "      <td>Metals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Kotak Mahindra Bank</td>\n",
              "      <td>KOTAKBANK.NS</td>\n",
              "      <td>Banking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Larsen &amp; Toubro</td>\n",
              "      <td>LT.NS</td>\n",
              "      <td>Construction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Mahindra &amp; Mahindra</td>\n",
              "      <td>M&amp;M.NS</td>\n",
              "      <td>Automobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Maruti Suzuki</td>\n",
              "      <td>MARUTI.NS</td>\n",
              "      <td>Automobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Nestlé India</td>\n",
              "      <td>NESTLEIND.NS</td>\n",
              "      <td>Consumer Goods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>NTPC</td>\n",
              "      <td>NTPC.NS</td>\n",
              "      <td>Energy - Power</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Oil and Natural Gas Corporation</td>\n",
              "      <td>ONGC.NS</td>\n",
              "      <td>Energy - Oil &amp; Gas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Power Grid Corporation of India</td>\n",
              "      <td>POWERGRID.NS</td>\n",
              "      <td>Energy - Power</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Reliance Industries</td>\n",
              "      <td>RELIANCE.NS</td>\n",
              "      <td>Energy - Oil &amp; Gas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>State Bank of India</td>\n",
              "      <td>SBIN.NS</td>\n",
              "      <td>Banking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>SBI Life Insurance Company</td>\n",
              "      <td>SBILIFE.NS</td>\n",
              "      <td>Insurance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Shree Cements</td>\n",
              "      <td>SHREECEM.NS</td>\n",
              "      <td>Cement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Sun Pharmaceutical</td>\n",
              "      <td>SUNPHARMA.NS</td>\n",
              "      <td>Pharmaceuticals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Tata Motors</td>\n",
              "      <td>TATAMOTORS.NS</td>\n",
              "      <td>Automobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Tata Steel</td>\n",
              "      <td>TATASTEEL.NS</td>\n",
              "      <td>Metals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Tata Consultancy Services</td>\n",
              "      <td>TCS.NS</td>\n",
              "      <td>Information Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Tata Consumer Products</td>\n",
              "      <td>TATACONSUM.NS</td>\n",
              "      <td>Consumer Goods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Tech Mahindra</td>\n",
              "      <td>TECHM.NS</td>\n",
              "      <td>Information Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Titan Company</td>\n",
              "      <td>TITAN.NS</td>\n",
              "      <td>Consumer Goods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>UltraTech Cement</td>\n",
              "      <td>ULTRACEMCO.NS</td>\n",
              "      <td>Cement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>United Phosphorus Limited</td>\n",
              "      <td>UPL.NS</td>\n",
              "      <td>Chemicals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Wipro</td>\n",
              "      <td>WIPRO.NS</td>\n",
              "      <td>Information Technology</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Adani Ports  ADANIPORTS.NS          Infrastructure\n",
              "0                      Asian Paints  ASIANPAINT.NS          Consumer Goods\n",
              "1                         Axis Bank    AXISBANK.NS                 Banking\n",
              "2                        Bajaj Auto  BAJAJ-AUTO.NS              Automobile\n",
              "3                     Bajaj Finance  BAJFINANCE.NS      Financial Services\n",
              "4                     Bajaj Finserv  BAJAJFINSV.NS      Financial Services\n",
              "5                     Bharti Airtel  BHARTIARTL.NS       Telecommunication\n",
              "6                  Bharat Petroleum        BPCL.NS      Energy - Oil & Gas\n",
              "7              Britannia Industries   BRITANNIA.NS          Consumer Goods\n",
              "8                             Cipla       CIPLA.NS         Pharmaceuticals\n",
              "9                        Coal India   COALINDIA.NS         Energy & Mining\n",
              "10              Divi's Laboratories    DIVISLAB.NS         Pharmaceuticals\n",
              "11         Dr. Reddy's Laboratories     DRREDDY.NS         Pharmaceuticals\n",
              "12                    Eicher Motors   EICHERMOT.NS              Automobile\n",
              "13                Grasim Industries      GRASIM.NS                  Cement\n",
              "14                 HCL Technologies     HCLTECH.NS  Information Technology\n",
              "15                             HDFC        HDFC.NS      Financial Services\n",
              "16                        HDFC Bank    HDFCBANK.NS                 Banking\n",
              "17                        HDFC Life    HDFCLIFE.NS               Insurance\n",
              "18                    Hero MotoCorp  HEROMOTOCO.NS              Automobile\n",
              "19              Hindalco Industries    HINDALCO.NS                  Metals\n",
              "20               Hindustan Unilever  HINDUNILVR.NS          Consumer Goods\n",
              "21                       ICICI Bank   ICICIBANK.NS                 Banking\n",
              "22                    IndusInd Bank  INDUSINDBK.NS                 Banking\n",
              "23                          Infosys        INFY.NS  Information Technology\n",
              "24           Indian Oil Corporation         IOC.NS      Energy - Oil & Gas\n",
              "25                      ITC Limited         ITC.NS          Consumer Goods\n",
              "26                        JSW Steel    JSWSTEEL.NS                  Metals\n",
              "27              Kotak Mahindra Bank   KOTAKBANK.NS                 Banking\n",
              "28                  Larsen & Toubro          LT.NS            Construction\n",
              "29              Mahindra & Mahindra         M&M.NS              Automobile\n",
              "30                    Maruti Suzuki      MARUTI.NS              Automobile\n",
              "31                     Nestlé India   NESTLEIND.NS          Consumer Goods\n",
              "32                             NTPC        NTPC.NS          Energy - Power\n",
              "33  Oil and Natural Gas Corporation        ONGC.NS      Energy - Oil & Gas\n",
              "34  Power Grid Corporation of India   POWERGRID.NS          Energy - Power\n",
              "35              Reliance Industries    RELIANCE.NS      Energy - Oil & Gas\n",
              "36              State Bank of India        SBIN.NS                 Banking\n",
              "37       SBI Life Insurance Company     SBILIFE.NS               Insurance\n",
              "38                    Shree Cements    SHREECEM.NS                  Cement\n",
              "39               Sun Pharmaceutical   SUNPHARMA.NS         Pharmaceuticals\n",
              "40                      Tata Motors  TATAMOTORS.NS              Automobile\n",
              "41                       Tata Steel   TATASTEEL.NS                  Metals\n",
              "42        Tata Consultancy Services         TCS.NS  Information Technology\n",
              "43           Tata Consumer Products  TATACONSUM.NS          Consumer Goods\n",
              "44                    Tech Mahindra       TECHM.NS  Information Technology\n",
              "45                    Titan Company       TITAN.NS          Consumer Goods\n",
              "46                 UltraTech Cement  ULTRACEMCO.NS                  Cement\n",
              "47        United Phosphorus Limited         UPL.NS               Chemicals\n",
              "48                            Wipro       WIPRO.NS  Information Technology"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeTeUn-kZe0-",
        "outputId": "f7112913-d890-4069-a633-914ac5d6ec94"
      },
      "source": [
        "#This is the main function for our WebApp\n",
        "\n",
        "%%writefile Stock_Market_Analysis_WebApp.py\n",
        "#MSE Imports\n",
        "import math\n",
        "import pandas_datareader as web\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import streamlit as st\n",
        "import yfinance as yf\n",
        "from fbprophet import Prophet\n",
        "from fbprophet.plot import plot_plotly, plot_components_plotly\n",
        "from plotly import graph_objs as go\n",
        "import pandas_datareader as web\n",
        "from datetime import date\n",
        "import datetime as dt\n",
        "import time\n",
        "\n",
        "#PAGE_CONFIG = {\"page_title\":\"StColab.io\",\"page_icon\":\":smiley:\",\"layout\":\"centered\"}\n",
        "#st.beta_set_page_config(**PAGE_CONFIG)\n",
        "\n",
        "def main():\n",
        "  \n",
        "  st.title('Grow All Star')\n",
        "\n",
        "  page = st.sidebar.selectbox('Select Page : ', ['Home', 'Financial Charts', 'Model Selection', 'Algorithmic Trading', 'Portfolio Optimization'] )\n",
        "  \n",
        "  stocks = (\"ADANIPORTS.NS\",\"ASIANPAINT.NS\",\"AXISBANK.NS\",\"BAJAJ-AUTO.NS\",\n",
        "          \"BAJFINANCE.NS\",\"BAJAJFINSV.NS\",\"BHARTIARTL.NS\",\"BPCL.NS\",\"BRITANNIA.NS\",\"CIPLA.NS\",\"COALINDIA.NS\",\n",
        "          \"DIVISLAB.NS\",\"DRREDDY.NS\",\"EICHERMOT.NS\",\"GRASIM.NS\",\"HCLTECH.NS\",\"HDFC.NS\",\"HDFCBANK.NS\",\"HDFCLIFE.NS\",\n",
        "          \"HEROMOTOCO.NS\",\"HINDALCO.NS\",\"HINDUNILVR.NS\",\"ICICIBANK.NS\",\"INDUSINDBK.NS\",\"INFY.NS\",\"IOC.NS\",\"ITC.NS\",\n",
        "          \"JSWSTEEL.NS\",\"KOTAKBANK.NS\",\"LT.NS\",\"M&M.NS\",\"MARUTI.NS\",\"NESTLEIND.NS\",\"NTPC.NS\",\"ONGC.NS\",\"POWERGRID.NS\",\n",
        "          \"RELIANCE.NS\",\"SBIN.NS\",\"SBILIFE.NS\",\"SHREECEM.NS\",\"SUNPHARMA.NS\",\"TATAMOTORS.NS\",\"TATASTEEL.NS\",\"TCS.NS\",\n",
        "          \"TATACONSUM.NS\",\"TECHM.NS\",\"TITAN.NS\",\"ULTRACEMCO.NS\",\"UPL.NS\",\"WIPRO.NS\")\n",
        "  \n",
        "  \n",
        "  selected_stock = st.sidebar.selectbox(\"Select Stock Ticker : \",stocks)\n",
        "  with st.spinner():\n",
        "    time.sleep(1)\n",
        "      \n",
        "  TODAY = date.today().strftime(\"%Y-%m-%d\")\n",
        "  START = st.sidebar.date_input(label = 'Start Date',value = dt.date(2019, 1, 1),min_value = dt.date(1992, 1, 1),max_value= date.today())\n",
        "  END = st.sidebar.date_input(label = 'End Date',min_value = dt.date(2000, 1, 1),max_value= date.today())\n",
        "  \n",
        "  @st.cache(allow_output_mutation=True) #Caching data\n",
        "  def load_data(ticker):\n",
        "    df = web.DataReader(ticker, data_source='yahoo', start = START , end = END)\n",
        "    return df\n",
        "      \n",
        "  data = load_data(selected_stock)\n",
        "    \n",
        "  layout = go.Layout(autosize=False, width=900, height=600, xaxis= go.layout.XAxis(linecolor = 'black',linewidth = 1,mirror = True),\n",
        "                       yaxis= go.layout.YAxis(linecolor = 'black',linewidth = 1,mirror = True),\n",
        "                       margin=go.layout.Margin(l=50,r=50,b=100,t=100,pad = 4))\n",
        "\n",
        "  if (page == 'Home'):\n",
        "    st.subheader('Data : ' + selected_stock.split('.')[0])\n",
        "    st.dataframe(data, 900, 300)\n",
        "\n",
        "    def plot_raw_data():\n",
        "      col_options = [\"High\", \"Low\", \"Open\", \"Close\",\"Volume\",\"Adj Close\"]\n",
        "      cols = st.multiselect(\"Select one or multiple Columns to visualize : \",col_options)\n",
        "      fig = go.Figure(layout = layout)\n",
        "      charts = []\n",
        "      for xxx in cols :\n",
        "        fig.add_trace(go.Scatter(x=data.index, y = data[xxx], name = 'Stock : '+xxx))\n",
        "        charts.append(xxx)\n",
        "      displayed = \", \".join(charts)\n",
        "      fig.layout.update(title_text = 'Interactive Stock Data Visualization of : ' + selected_stock.split('.')[0] + \" : \" + displayed  , xaxis_rangeslider_visible = True, yaxis_title='Stock : ' + selected_stock.split('.')[0] + ' : Open and Close Price')\n",
        "      st.plotly_chart(fig)\n",
        "\n",
        "    plot_raw_data()\n",
        "      \n",
        "  elif page == 'Financial Charts':\n",
        "\n",
        "    charts = [\"None\",\"Candlestick\", \"Open-High-Low-Close\"]\n",
        "\n",
        "    st.subheader('Financial Charts - Stock : ' + selected_stock.split('.')[0])\n",
        "\n",
        "    chart_type = st.selectbox(\"Select Chart type to visualize in the period\",charts)\n",
        "    with st.spinner():\n",
        "      time.sleep(1)\n",
        "    #fig = go.Figure()    \n",
        "    if chart_type == 'Candlestick':\n",
        "      fig = go.Figure(data=[go.Candlestick(x=data.index, open=data['Open'], high=data['High'], low=data['Low'], close=data['Close'])])\n",
        "\n",
        "      fig.update_layout(width=900, height=600, title= 'CandleStick Chart : ' + selected_stock.split('.')[0], yaxis_title='STOCK : ' + selected_stock.split('.')[0])\n",
        "    \n",
        "      st.plotly_chart(fig)\n",
        "\n",
        "    if chart_type == 'Open-High-Low-Close':\n",
        "      fig = go.Figure(data=[go.Ohlc(x=data.index, open=data['Open'], high=data['High'], low=data['Low'], close=data['Close'])])\n",
        "          \n",
        "      fig.update_layout(width=900, height=600, title='Open-High-Low-Close Chart : ' + selected_stock.split('.')[0], yaxis_title='STOCK : ' + selected_stock.split('.')[0])\n",
        "\n",
        "      st.plotly_chart(fig)\n",
        "      \n",
        "    else:\n",
        "      st.text(\"Select From above box which Financial Chart to Display.\")\n",
        "\n",
        "  elif page == 'Model Selection':\n",
        "    \n",
        "    #Function 1 : Forecasting in Facebook Prophet Method\n",
        "      \n",
        "    def Prophet_model():\n",
        "      n_days = st.sidebar.slider(\"No. of days for prediction:\", 1, 28)\n",
        "      period = n_days #To be in days.\n",
        "      df = data.copy(deep = True)\n",
        "      df.reset_index(inplace = True)\n",
        "      df_train = df[['Date', 'Close']]\n",
        "      df_train = df_train.rename(columns = {\"Date\":\"ds\",\"Close\":\"y\"})\n",
        "      m=Prophet()\n",
        "      m.fit(df_train)\n",
        "      future = m.make_future_dataframe(periods = period)\n",
        "      forecast = m.predict(future)\n",
        "\n",
        "      st.subheader('Forecast data')\n",
        "      st.write(forecast.tail())\n",
        "\n",
        "      st.write('Forecasted Data')\n",
        "      fig1 = plot_plotly(m, forecast)\n",
        "      #st.plotly_chart(fig1)\n",
        "\n",
        "      choice = ('No','Yes')\n",
        "      choice_select= st.sidebar.selectbox('Display Forecast Components:',choice)\n",
        "    \n",
        "      if choice_select == 'No':\n",
        "        st.write('Select Yes to display Trend, Seasonality and Randomness.')\n",
        "        fig2 = -1\n",
        "        return (forecast, fig1, fig2)\n",
        "      else:\n",
        "        st.write('Forecast Components')\n",
        "        #fig2 = m.plot_components(forecast)\n",
        "        fig2 = plot_components_plotly(m, forecast)\n",
        "        #st.write(fig2)\n",
        "      return (forecast, fig1, fig2)\n",
        "        \n",
        "    #Function 2 : Forecasting in Multi-Variate Regression\n",
        "    \n",
        "    def Multi_Variate_Regression(df1):\n",
        "      df = df1.copy(deep = True)\n",
        "      df.reset_index(inplace = True)\n",
        "\n",
        "      #Sequential Split for Train and Test Data : Give it inside every UDF.\n",
        "      test_ratio = st.sidebar.slider(\"Test Ratio : for Sequential Split:\", 0.1, 0.9)\n",
        "      test_size = round(test_ratio * len(df))\n",
        "      st.write('Test Size :' ,test_size)\n",
        "      st.write('Train Size :' ,len(df) - test_size)\n",
        "\n",
        "      # Create traces\n",
        "      fig1 = go.Figure(layout = layout)\n",
        "      fig1.add_trace(go.Scatter(y=df[\"Close\"], x=df.Date,mode='lines',name='Closed price History' ))\n",
        "\n",
        "      fig1.layout.update(title_text = 'Closed price History : ' + selected_stock.split('.')[0] , \n",
        "                         xaxis_rangeslider_visible = True, yaxis_title='Stock : ' + selected_stock.split('.')[0] + ' :Close Price(INR)', xaxis_title='Timeline')\n",
        "    \n",
        "      # Create traces\n",
        "      fig2 = go.Figure(layout = layout)\n",
        "      fig2.add_trace(go.Scatter(y=df[\"Volume\"], x=df.Date, mode='lines',name='Stock Purchased Voume' ))\n",
        "    \n",
        "      fig2.layout.update(title_text = 'Stock Volume traded History : ' + selected_stock.split('.')[0] , \n",
        "                           xaxis_rangeslider_visible = True, yaxis_title='Stock Volume : ' + selected_stock.split('.')[0], xaxis_title='Timeline')\n",
        "    \n",
        "      # Create a new dataframe with a close column\n",
        "      data = df.filter(['Close'])\n",
        "      dataset = data.values\n",
        "      training_data_len = round(len(dataset)* 0.8)\n",
        "    \n",
        "      #Remove date and Adj Close columns, it seems date is not an actual column here. cannot be dropped\n",
        "      data = df.drop(['Adj Close'],axis = 1)\n",
        "      df=df.drop(['Adj Close'],axis = 1)\n",
        "      dataset = data.values\n",
        "      features = ['High', 'Low', 'Open', 'Volume']\n",
        "      x = df.loc[:, features].values\n",
        "      y = df.loc[:, ['Close']].values\n",
        "      x = StandardScaler().fit_transform(x)\n",
        "    \n",
        "      #Perform PCA\n",
        "      pca = PCA(n_components=2)\n",
        "      principalComponents = pca.fit_transform(x)\n",
        "      principalDataframe = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2'])\n",
        "      #principalDataframe\n",
        "    \n",
        "      targetDataframe = df[['Close']]\n",
        "      newDataframe = targetDataframe\n",
        "      targetDataframe[['PC1','PC2']]=principalDataframe[['PC1','PC2']]\n",
        "    \n",
        "      #Split into train and test data\n",
        "      data_X = targetDataframe.loc[:,targetDataframe.columns !=  'Close' ]\n",
        "      data_Y = targetDataframe['Close']\n",
        "      sp = int(test_ratio * len(data_X))\n",
        "      train_X = data_X[0:-sp]\n",
        "      test_X = data_X[-sp:]\n",
        "      train_Y = data_Y[0:-sp]\n",
        "      test_Y = data_Y[-sp:]\n",
        "    \n",
        "      # Convert x_train and y_train to numpy array.\n",
        "      train_X, train_Y = np.array(train_X), np.array(train_Y)\n",
        "      test_X, test_Y = np.array(test_X), np.array(test_Y)\n",
        "    \n",
        "      #Creating the Regressor\n",
        "      regressor = LinearRegression(n_jobs=-1, normalize=True)\n",
        "      regressor.fit(train_X,train_Y)\n",
        "    \n",
        "      #Make Predictions and Evaluate the results\n",
        "      predict_Y = regressor.predict(test_X)\n",
        "      r2 = regressor.score(test_X,test_Y)\n",
        "      MeanSqError = mean_squared_error(test_Y,predict_Y)\n",
        "      Slope = regressor.coef_\n",
        "      Intercept = regressor.intercept_\n",
        "      RMSE = np.sqrt(MeanSqError)\n",
        "    \n",
        "      df_results = pd.DataFrame({'Predicted': predict_Y, 'Actual': test_Y, 'Accuracy':100*(predict_Y)/test_Y })\n",
        "      df_results.sort_values(by='Actual',axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
        "      #df_results\n",
        "      #https://plotly.com/python/line-charts/\n",
        "      # Create traces\n",
        "\n",
        "      fig3 = go.Figure(layout = layout)\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Actual\"], x=df[-sp:].Date, mode='lines', name='Actual'))\n",
        "    \n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Predicted\"], x=df[-sp:].Date, mode='lines', name='Predicted'))\n",
        "\n",
        "      fig3.layout.update(title_text = 'Prediction on Test data ' + selected_stock.split('.')[0] , \n",
        "                           xaxis_rangeslider_visible = True, \n",
        "                           yaxis_title='Closed Price : ' + selected_stock.split('.')[0],\n",
        "                           xaxis_title='Timeline')\n",
        "    \n",
        "      st.write(\"Prediction Results on test data on a Data Frame : \")\n",
        "\n",
        "      #Link : https://medium.com/daily-python/simple-stock-prediction-using-linear-regression-in-python-daily-python-18-ecfe23b76ce9\n",
        "      df\n",
        "    \n",
        "      return (regressor, fig1, fig2, fig3,r2 ,RMSE, Intercept, Slope[0], df_results) #Returns 8 values - regressor, 3 Plots and Test-Outputs.\n",
        "      \n",
        "      \n",
        "    #Function 3 : Random-Forest - 1-day into the future.\n",
        "\n",
        "    def Random_Forest(df_1):\n",
        "      import plotly.graph_objects as go\n",
        "      df = df_1.copy(deep=True)\n",
        "      df['Date'] = df.index\n",
        "\n",
        "      #Sequential Split for Train and Test Data : Give it inside every UDF.\n",
        "      test_ratio = st.sidebar.slider(\"Test Ratio : for Sequential Split:\", 0.1, 0.9)\n",
        "      test_size = round(test_ratio * len(df))\n",
        "      st.write('Test Size :' ,test_size)\n",
        "      st.write('Train Size :' ,len(df) - test_size)\n",
        "\n",
        "      # Create traces\n",
        "      fig1 = go.Figure(layout = layout)\n",
        "      fig1.add_trace(go.Scatter(y=df[\"Close\"], x=df.Date,mode='lines',name='Closed price History' ))\n",
        "        \n",
        "      fig1.layout.update(title_text = 'Closed price History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock : ' + selected_stock.split('.')[0] + ' :Close Price(INR)',\n",
        "                       xaxis_title='Timeline')\n",
        "      # Create traces\n",
        "      fig2 = go.Figure(layout = layout)\n",
        "      fig2.add_trace(go.Scatter(y=df[\"Volume\"], x=df.Date,\n",
        "                              mode='lines',name='Stock Purchased Voume' ))\n",
        "      fig2.layout.update(title_text = 'Stock Volume traded History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock Volume : ' + selected_stock.split('.')[0], xaxis_title='Timeline')\n",
        "\n",
        "    \n",
        "    \n",
        "      df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
        "      df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
        "      df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
        "\n",
        "      #Will predict this with a day ago value of Adj Close\n",
        "      df['Adj Close 1 Day Future'] = df['Adj Close'].shift(1)\n",
        "      df.drop(['Open','High','Low','Close'],inplace = True,axis = 1)\n",
        "\n",
        "      df=  df.dropna()\n",
        "      target = df['Adj Close 1 Day Future']\n",
        "      df1 = df.drop(['Date'],axis=1)\n",
        "      df1.drop(['Adj Close 1 Day Future'],axis = 1)\n",
        "      df1['Adj Close 1 Day Future'] = target\n",
        "      df2 = df1.dropna()\n",
        "\n",
        "      # Rounded value of 20% of length of df2 for splitting\n",
        "      sp = round(test_ratio * len(df2))\n",
        "      train = df2[:-sp]\n",
        "      test = df2[-sp:]\n",
        "      train_X = train.iloc[:,0:-1]\n",
        "      train_y = train.iloc[:,-1]\n",
        "      test_X = test.iloc[:,0:-1]\n",
        "      test_y = test.iloc[:,-1]\n",
        "      regressor = RandomForestRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
        "                                          max_depth=11, max_features=1.0, max_leaf_nodes=None,\n",
        "                                          max_samples=None, min_impurity_decrease=0,\n",
        "                                          min_impurity_split=None, min_samples_leaf=4,\n",
        "                                          min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
        "                                          n_estimators=140, n_jobs=-1, oob_score=False,\n",
        "                                          random_state=4936, verbose=0, warm_start=False)\n",
        "      #regressor = RandomForestRegressor()\n",
        "      regressor.fit(train_X,train_y)\n",
        "      from sklearn.metrics import mean_squared_error\n",
        "      predict_Y = regressor.predict(test_X)\n",
        "      r2 = regressor.score(test_X,test_y)\n",
        "      error = mean_squared_error(test_y,predict_Y)\n",
        "   \n",
        "      RMSE = np.sqrt(error)\n",
        "      df_results = pd.DataFrame({'Predicted': predict_Y, 'Actual': test_y, 'Accuracy':100*(predict_Y)/test_y })\n",
        "      df_results.sort_values(by='Actual',axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
        "      import plotly.express as px\n",
        "      import plotly.graph_objects as go\n",
        "      # Create traces\n",
        "      fig3 = go.Figure()\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Actual\"], x=df[-sp:].Date, mode='lines', name='Actual'))\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Predicted\"], x=df[-sp:].Date,mode='lines',name='Predicted'))\n",
        "\n",
        "      fig3.layout.update(title_text = 'Prediction on Test data ' + selected_stock.split('.')[0] , \n",
        "                           xaxis_rangeslider_visible = True, width=900, height=600, \n",
        "                           yaxis_title='Closed Price : ' + selected_stock.split('.')[0],xaxis_title='TIMELINE')\n",
        "      #fig3.show()\n",
        "      df\n",
        "      return (regressor, fig1, fig2, fig3,r2 ,RMSE, df_results)\n",
        "      \n",
        "    # Function 4 - Bayesian Ridge - 1-day into the future.\n",
        "\n",
        "    def Bayesian_Ridge(df_1):\n",
        "      import plotly.graph_objects as go\n",
        "      df = df_1.copy(deep=True)\n",
        "      #Sequential Split for Train and Test Data : Give it inside every UDF.\n",
        "      test_ratio = st.sidebar.slider(\"Test Ratio : for Sequential Split:\", 0.1, 0.9)\n",
        "      test_size = round(test_ratio * len(df))\n",
        "      st.write('Test Size :' ,test_size)\n",
        "      st.write('Train Size :' ,len(df) - test_size)\n",
        "      df['Date'] = df.index\n",
        "\n",
        "      # Create traces\n",
        "      fig1 = go.Figure(layout = layout)\n",
        "      fig1.add_trace(go.Scatter(y=df[\"Close\"], x=df.Date,mode='lines',name='Closed price History' ))\n",
        "      fig1.layout.update(title_text = 'Closed price History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock : ' + selected_stock.split('.')[0] + ' :Close Price(INR)',\n",
        "                       xaxis_title='Timeline')\n",
        "      # Create traces\n",
        "      fig2 = go.Figure(layout = layout)\n",
        "      fig2.add_trace(go.Scatter(y=df[\"Volume\"], x=df.Date,\n",
        "                              mode='lines',name='Stock Purchased Voume' ))\n",
        "      fig2.layout.update(title_text = 'Stock Volume traded History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock Volume : ' + selected_stock.split('.')[0], xaxis_title='Timeline')\n",
        "\n",
        "    \n",
        "      df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
        "      df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
        "      df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
        "      #Will predict this with a day ago value of Adj Close\n",
        "      df['Adj Close 1 Day Future'] = df['Adj Close'].shift(1)\n",
        "      df.drop(['Open','High','Low','Close'],inplace = True,axis = 1)\n",
        "\n",
        "      df=  df.dropna()\n",
        "      target = df['Adj Close 1 Day Future']\n",
        "      df1 = df.drop(['Date'],axis=1)\n",
        "      df1.drop(['Adj Close 1 Day Future'],axis = 1)\n",
        "      df1['Adj Close 1 Day Future'] = target\n",
        "      df2 = df1.dropna()\n",
        "      # Rounded value of 20% of length of df2 for splitting\n",
        "      sp = round(test_ratio * len(df2))\n",
        "      train = df2[:-sp]\n",
        "      test = df2[-sp:]\n",
        "      train_X = train.iloc[:,0:-1]\n",
        "      train_y = train.iloc[:,-1]\n",
        "      test_X = test.iloc[:,0:-1]\n",
        "      test_y = test.iloc[:,-1]\n",
        "      regressor = BayesianRidge(alpha_1=0.01, alpha_2=0.1, alpha_init=None, compute_score=False,\n",
        "              copy_X=True, fit_intercept=False, lambda_1=0.05, lambda_2=0.05,\n",
        "              lambda_init=None, n_iter=300, normalize=False, tol=0.001,\n",
        "              verbose=False)\n",
        "      regressor.fit(train_X,train_y)\n",
        "      predict_Y = regressor.predict(test_X)\n",
        "      error = mean_squared_error(test_y,predict_Y)\n",
        "      RMSE = np.sqrt(error)\n",
        "\n",
        "      Slope = regressor.coef_\n",
        "      Intercept = regressor.intercept_\n",
        "      r2 = regressor.score(test_X,test_y)\n",
        "      df_results = pd.DataFrame({'Predicted': predict_Y, 'Actual': test_y, 'Accuracy':100*(predict_Y)/test_y })\n",
        "      df_results.sort_values(by='Actual',axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
        "\n",
        "      fig3 = go.Figure()\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Actual\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Actual'))\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Predicted\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Predicted'))\n",
        "      fig3.layout.update(title_text = 'Prediction on Test data ' + selected_stock.split('.')[0] , \n",
        "                  xaxis_rangeslider_visible = True, width=900, height=600, \n",
        "                  yaxis_title='Closed Price : ' + selected_stock.split('.')[0],\n",
        "                  xaxis_title='Timeline')\n",
        "    \n",
        "      df\n",
        "      return (regressor, fig1, fig2, fig3,r2 ,RMSE,Intercept, Slope[0], df_results)\n",
        "      \n",
        "    # Function 5 - Orthogonal Matching Pursuit - 1-day into the future.\n",
        "    \n",
        "    def Orthogonal_Matching_Pursuit(df_1):\n",
        "      import plotly.graph_objects as go\n",
        "      df = df_1.copy(deep=True)\n",
        "\n",
        "      #Sequential Split for Train and Test Data : Give it inside every UDF.\n",
        "      test_ratio = st.sidebar.slider(\"Test Ratio : for Sequential Split:\", 0.1, 0.9)\n",
        "      test_size = round(test_ratio * len(df))\n",
        "      st.write('Test Size :' ,test_size)\n",
        "      st.write('Train Size :' ,len(df) - test_size)\n",
        "      df['Date'] = df.index\n",
        "\n",
        "      # Create traces\n",
        "      fig1 = go.Figure(layout = layout)\n",
        "      fig1.add_trace(go.Scatter(y=df[\"Close\"], x=df.Date,mode='lines',name='Closed price History' ))\n",
        "      fig1.layout.update(title_text = 'Closed price History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock : ' + selected_stock.split('.')[0] + ' :Close Price(INR)',\n",
        "                       xaxis_title='Timeline')\n",
        "      # Create traces\n",
        "      fig2 = go.Figure(layout = layout)\n",
        "      fig2.add_trace(go.Scatter(y=df[\"Volume\"], x=df.Date,\n",
        "                              mode='lines',name='Stock Purchased Voume' ))\n",
        "      fig2.layout.update(title_text = 'Stock Volume traded History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock Volume : ' + selected_stock.split('.')[0], xaxis_title='Timeline')\n",
        "\n",
        "      df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
        "      df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
        "      df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
        "      #Will predict this with a day ago value of Adj Close\n",
        "      df['Adj Close 1 Day Future'] = df['Adj Close'].shift(1)\n",
        "      df.drop(['Open','High','Low','Close'],inplace = True,axis = 1)\n",
        "\n",
        "      df=  df.dropna()\n",
        "      target = df['Adj Close 1 Day Future']\n",
        "      df1 = df.drop(['Date'],axis=1)\n",
        "      df1.drop(['Adj Close 1 Day Future'],axis = 1)\n",
        "      df1['Adj Close 1 Day Future'] = target\n",
        "      df2 = df1.dropna()\n",
        "      # Rounded value of 20% of length of df2 for splitting\n",
        "      sp = round(test_ratio * len(df2))\n",
        "      train = df2[:-sp]\n",
        "      test = df2[-sp:]\n",
        "      train_X = train.iloc[:,0:-1]\n",
        "      train_y = train.iloc[:,-1]\n",
        "      test_X = test.iloc[:,0:-1]\n",
        "      test_y = test.iloc[:,-1]\n",
        "    \n",
        "      regressor = OrthogonalMatchingPursuit()\n",
        "      regressor.fit(train_X,train_y)\n",
        "      predict_Y = regressor.predict(test_X)\n",
        "      error = mean_squared_error(test_y,predict_Y)\n",
        "      RMSE = np.sqrt(error)\n",
        "      r2 = regressor.score(test_X,test_y)\n",
        "      Slope = regressor.coef_\n",
        "      Intercept = regressor.intercept_\n",
        "      df_results = pd.DataFrame({'Predicted': predict_Y, 'Actual': test_y, 'Accuracy':100*(predict_Y)/test_y })\n",
        "      df_results.sort_values(by='Actual',axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
        "\n",
        "      import plotly.express as px\n",
        "      import plotly.graph_objects as go\n",
        "    \n",
        "      # Create traces\n",
        "      fig3 = go.Figure()\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Actual\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Actual'))\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Predicted\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Predicted'))\n",
        "      fig3.layout.update(title_text = 'Prediction on Test data ' + selected_stock.split('.')[0] , \n",
        "                  xaxis_rangeslider_visible = True, width=900, height=600, \n",
        "                  yaxis_title='Closed Price : ' + selected_stock.split('.')[0],\n",
        "                  xaxis_title='Timeline')\n",
        "      #fig3.show()\n",
        "      df\n",
        "\n",
        "      return (regressor, fig1, fig2, fig3,r2 ,RMSE,Intercept,Slope[0], df_results)\n",
        "    \n",
        "    # Function 6 - Ridge - 1-day into the future.\n",
        "    \n",
        "    def Ridge(df_1):\n",
        "      import plotly.express as px\n",
        "      import plotly.graph_objects as go\n",
        "      df = df_1.copy(deep=True)\n",
        "\n",
        "      #Sequential Split for Train and Test Data : Give it inside every UDF.\n",
        "      test_ratio = st.sidebar.slider(\"Test Ratio : for Sequential Split:\", 0.1, 0.9)\n",
        "      test_size = round(test_ratio * len(df))\n",
        "      st.write('Test Size :' ,test_size)\n",
        "      st.write('Train Size :' ,len(df) - test_size)\n",
        "      df['Date'] = df.index\n",
        "\n",
        "      # Create traces\n",
        "      fig1 = go.Figure(layout = layout)\n",
        "      fig1.add_trace(go.Scatter(y=df[\"Close\"], x=df.Date,mode='lines',name='Closed price History' ))\n",
        "      fig1.layout.update(title_text = 'Closed price History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock : ' + selected_stock.split('.')[0] + ' :Close Price(INR)',\n",
        "                       xaxis_title='Timeline')\n",
        "      # Create traces\n",
        "      fig2 = go.Figure(layout = layout)\n",
        "      fig2.add_trace(go.Scatter(y=df[\"Volume\"], x=df.Date,\n",
        "                              mode='lines',name='Stock Purchased Voume' ))\n",
        "      fig2.layout.update(title_text = 'Stock Volume traded History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock Volume : ' + selected_stock.split('.')[0], xaxis_title='Timeline')\n",
        "\n",
        "      df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
        "      df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
        "      df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
        "\n",
        "      #Will predict this with a day ago value of Adj Close\n",
        "      df['Adj Close 1 Day Future'] = df['Adj Close'].shift(1)\n",
        "      df.drop(['Open','High','Low','Close'],inplace = True,axis = 1)\n",
        "      df=  df.dropna()\n",
        "      target = df['Adj Close 1 Day Future'] \n",
        "      df1 = df.drop(['Date'],axis=1)\n",
        "      df1.drop(['Adj Close 1 Day Future'],axis = 1)\n",
        "      df1['Adj Close 1 Day Future'] = target\n",
        "      df2 = df1.dropna()\n",
        "      # Rounded value of 20% of length of df2 for splitting\n",
        "      sp = round(test_ratio * len(df2))\n",
        "      train = df2[:-sp]\n",
        "      test = df2[-sp:]\n",
        "      train_X = train.iloc[:,0:-1]\n",
        "      train_y = train.iloc[:,-1]\n",
        "      test_X = test.iloc[:,0:-1]\n",
        "      test_y = test.iloc[:,-1]\n",
        "\n",
        "      from sklearn.linear_model import Ridge\n",
        "      #alpha=2.26, copy_X=True, fit_intercept=False, max_iter=None, normalize=False, random_state=4265, solver='auto', tol=0.001\n",
        "\n",
        "      regressor = Ridge()\n",
        "      regressor.fit(train_X,train_y)\n",
        "      predict_Y = regressor.predict(test_X)\n",
        "      error = mean_squared_error(test_y,predict_Y)\n",
        "      Slope = regressor.coef_\n",
        "      RMSE = np.sqrt(error)\n",
        "      r2 = regressor.score(test_X,test_y)\n",
        "      Intercept = regressor.intercept_\n",
        "      df_results = pd.DataFrame({'Predicted': predict_Y, 'Actual': test_y, 'Accuracy':100*(predict_Y)/test_y })\n",
        "      df_results.sort_values(by='Actual',axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
        "  \n",
        "      # Create traces\n",
        "      fig3 = go.Figure()\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Actual\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Actual'))\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Predicted\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Predicted'))\n",
        "      fig3.layout.update(title_text = 'Prediction on Test data ' + selected_stock.split('.')[0] , \n",
        "                  xaxis_rangeslider_visible = True, width=900, height=600, \n",
        "                  yaxis_title='Closed Price : ' + selected_stock.split('.')[0],\n",
        "                  xaxis_title='Timeline')\n",
        "      #fig3.show()\n",
        "      df\n",
        "\n",
        "      return (regressor, fig1, fig2, fig3,r2 ,RMSE,Intercept,Slope[0], df_results)\n",
        "      \n",
        "      # Function 7 - XgBoost Regression - 1 day into the future.\n",
        "\n",
        "    def XgBoost_Regressor(df_1):\n",
        "      from sklearn.ensemble import GradientBoostingRegressor\n",
        "      import plotly.graph_objects as go\n",
        "      df = df_1.copy(deep=True)\n",
        "      df['Date'] = df.index\n",
        "\n",
        "      #Sequential Split for Train and Test Data : Give it inside every UDF.\n",
        "      test_ratio = st.sidebar.slider(\"Test Ratio : for Sequential Split:\", 0.1, 0.9)\n",
        "      test_size = round(test_ratio * len(df))\n",
        "      st.write('Test Size :' ,test_size)\n",
        "      st.write('Train Size :' ,len(df) - test_size)\n",
        "\n",
        "      # Create traces\n",
        "      fig1 = go.Figure(layout = layout)\n",
        "      fig1.add_trace(go.Scatter(y=df[\"Close\"], x=df.Date,mode='lines',name='Closed price History' ))\n",
        "      fig1.layout.update(title_text = 'Closed price History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock : ' + selected_stock.split('.')[0] + ' :Close Price(INR)',\n",
        "                       xaxis_title='Timeline')\n",
        "      # Create traces\n",
        "      fig2 = go.Figure(layout = layout)\n",
        "      fig2.add_trace(go.Scatter(y=df[\"Volume\"], x=df.Date,\n",
        "                              mode='lines',name='Stock Purchased Voume' ))\n",
        "      fig2.layout.update(title_text = 'Stock Volume traded History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock Volume : ' + selected_stock.split('.')[0], xaxis_title='Timeline')\n",
        "\n",
        "    \n",
        "    \n",
        "      df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
        "      df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
        "      df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
        "\n",
        "      #Will predict this with a day ago value of Adj Close\n",
        "      df['Adj Close 1 Day Future'] = df['Adj Close'].shift(1)\n",
        "      df.drop(['Open','High','Low','Close'],inplace = True,axis = 1)\n",
        "\n",
        "      df =  df.dropna()\n",
        "      target = df['Adj Close 1 Day Future']\n",
        "      df1 = df.drop(['Date'],axis=1)\n",
        "      df1.drop(['Adj Close 1 Day Future'],axis = 1)\n",
        "      df1['Adj Close 1 Day Future'] = target\n",
        "      df2 = df1.dropna()\n",
        "\n",
        "      # Rounded value of 20% of length of df2 for splitting\n",
        "      sp = round(test_ratio * len(df2))\n",
        "      train = df2[:-sp]\n",
        "      test = df2[-sp:]\n",
        "      train_X = train.iloc[:,0:-1]\n",
        "      train_y = train.iloc[:,-1]\n",
        "      test_X = test.iloc[:,0:-1]\n",
        "      test_y = test.iloc[:,-1]\n",
        "      regressor = GradientBoostingRegressor()\n",
        "\n",
        "      regressor.fit(train_X,train_y)\n",
        "      from sklearn.metrics import mean_squared_error\n",
        "      predict_Y = regressor.predict(test_X)\n",
        "      r2 = regressor.score(test_X,test_y)\n",
        "      error = mean_squared_error(test_y,predict_Y)\n",
        "      RMSE = np.sqrt(error)\n",
        "      df_results = pd.DataFrame({'Predicted': predict_Y, 'Actual': test_y, 'Accuracy':100*(predict_Y)/test_y })\n",
        "      df_results.sort_values(by='Actual',axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
        "      import plotly.express as px\n",
        "      import plotly.graph_objects as go\n",
        "      # Create traces\n",
        "      fig3 = go.Figure()\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Actual\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Actual'))\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Predicted\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Predicted'))\n",
        "      fig3.layout.update(title_text = 'Prediction on Test data ' + selected_stock.split('.')[0] , \n",
        "                  xaxis_rangeslider_visible = True, width=900, height=600, \n",
        "                  yaxis_title='Closed Price : ' + selected_stock.split('.')[0],\n",
        "                  xaxis_title='Timeline')\n",
        "      #fig3.show()\n",
        "      df\n",
        "      return (regressor, fig1, fig2, fig3,r2 ,RMSE, df_results)\n",
        "      \n",
        "    # Function 8 - Extra Trees Regressor - 1 day into the future\n",
        "    \n",
        "    def Extra_Trees_Regressor(df_1):\n",
        "      from sklearn.ensemble import ExtraTreesRegressor\n",
        "      import plotly.graph_objects as go\n",
        "      df = df_1.copy(deep=True)\n",
        "      df['Date'] = df.index\n",
        "    \n",
        "      #Sequential Split for Train and Test Data : Give it inside every UDF.\n",
        "      test_ratio = st.sidebar.slider(\"Test Ratio : for Sequential Split:\", 0.1, 0.9)\n",
        "      test_size = round(test_ratio * len(df))\n",
        "      st.write('Test Size :' ,test_size)\n",
        "      st.write('Train Size :' ,len(df) - test_size)\n",
        "    \n",
        "      # Create traces\n",
        "      fig1 = go.Figure(layout = layout)\n",
        "      fig1.add_trace(go.Scatter(y=df[\"Close\"], x=df.Date,mode='lines',name='Closed price History' ))\n",
        "      fig1.layout.update(title_text = 'Closed price History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock : ' + selected_stock.split('.')[0] + ' :Close Price(INR)',\n",
        "                       xaxis_title='Timeline')\n",
        "      # Create traces\n",
        "      fig2 = go.Figure(layout = layout)\n",
        "      fig2.add_trace(go.Scatter(y=df[\"Volume\"], x=df.Date,\n",
        "                              mode='lines',name='Stock Purchased Voume' ))\n",
        "      fig2.layout.update(title_text = 'Stock Volume traded History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock Volume : ' + selected_stock.split('.')[0], xaxis_title='Timeline')\n",
        "\n",
        "    \n",
        "      df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
        "      df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
        "      df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
        "\n",
        "      #Will predict this with a day ago value of Adj Close\n",
        "      df['Adj Close 1 Day Future'] = df['Adj Close'].shift(1)\n",
        "      df.drop(['Open','High','Low','Close'],inplace = True,axis = 1)\n",
        "\n",
        "\n",
        "      df=  df.dropna()\n",
        "      target = df['Adj Close 1 Day Future']\n",
        "      df1 = df.drop(['Date'],axis=1)\n",
        "      df1.drop(['Adj Close 1 Day Future'],axis = 1)\n",
        "      df1['Adj Close 1 Day Future'] = target\n",
        "      df2 = df1.dropna()\n",
        "\n",
        "      # Rounded value of 20% of length of df2 for splitting\n",
        "      sp = round(test_ratio * len(df2))\n",
        "      train = df2[:-sp]\n",
        "      test = df2[-sp:]\n",
        "      train_X = train.iloc[:,0:-1]\n",
        "      train_y = train.iloc[:,-1]\n",
        "      test_X = test.iloc[:,0:-1]\n",
        "      test_y = test.iloc[:,-1]\n",
        "      regressor = GradientBoostingRegressor()\n",
        "\n",
        "      regressor.fit(train_X,train_y)\n",
        "      from sklearn.metrics import mean_squared_error\n",
        "      predict_Y = regressor.predict(test_X)\n",
        "      r2 = regressor.score(test_X,test_y)\n",
        "      error = mean_squared_error(test_y,predict_Y)\n",
        "\n",
        "      RMSE = np.sqrt(error)\n",
        "      df_results = pd.DataFrame({'Predicted': predict_Y, 'Actual': test_y, 'Accuracy':100*(predict_Y)/test_y })\n",
        "      df_results.sort_values(by='Actual',axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
        "      import plotly.express as px\n",
        "      import plotly.graph_objects as go\n",
        "      # Create traces\n",
        "      fig3 = go.Figure()\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Actual\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Actual'))\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Predicted\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Predicted'))\n",
        "      fig3.layout.update(title_text = 'Prediction on Test data ' + selected_stock.split('.')[0] , \n",
        "                  xaxis_rangeslider_visible = True, width=900, height=600, \n",
        "                  yaxis_title='Closed Price : ' + selected_stock.split('.')[0],\n",
        "                  xaxis_title='Timeline')\n",
        "      #fig3.show()\n",
        "      df\n",
        "      return (regressor, fig1, fig2, fig3,r2 ,RMSE, df_results)\n",
        "      \n",
        "    # Function 9 - Adaboost Regressor - 1 day into the future.\n",
        "    \n",
        "    def AdaBoost_Regressor(df_1):\n",
        "      \n",
        "      from sklearn.ensemble import AdaBoostRegressor\n",
        "      import plotly.graph_objects as go\n",
        "      df = df_1.copy(deep=True)\n",
        "      df['Date'] = df.index\n",
        "\n",
        "      #Sequential Split for Train and Test Data : Give it inside every UDF.\n",
        "      test_ratio = st.sidebar.slider(\"Test Ratio : for Sequential Split:\", 0.1, 0.9)\n",
        "      test_size = round(test_ratio * len(df))\n",
        "      st.write('Test Size :' ,test_size)\n",
        "      st.write('Train Size :' ,len(df) - test_size)\n",
        "\n",
        "      # Create traces\n",
        "      fig1 = go.Figure(layout = layout)\n",
        "      fig1.add_trace(go.Scatter(y=df[\"Close\"], x=df.Date,mode='lines',name='Closed price History' ))\n",
        "      fig1.layout.update(title_text = 'Closed price History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock : ' + selected_stock.split('.')[0] + ' :Close Price(INR)',\n",
        "                       xaxis_title='Timeline')\n",
        "      # Create traces\n",
        "      fig2 = go.Figure(layout = layout)\n",
        "      fig2.add_trace(go.Scatter(y=df[\"Volume\"], x=df.Date,\n",
        "                              mode='lines',name='Stock Purchased Voume' ))\n",
        "      fig2.layout.update(title_text = 'Stock Volume traded History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock Volume : ' + selected_stock.split('.')[0], xaxis_title='Timeline')\n",
        "\n",
        "    \n",
        "    \n",
        "      df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
        "      df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
        "      df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
        "\n",
        "      #Will predict this with a day ago value of Adj Close\n",
        "      df['Adj Close 1 Day Future'] = df['Adj Close'].shift(1)\n",
        "      df.drop(['Open','High','Low','Close'],inplace = True,axis = 1)\n",
        "\n",
        "      df=  df.dropna()\n",
        "      target = df['Adj Close 1 Day Future']\n",
        "      df1 = df.drop(['Date'],axis=1)\n",
        "      df1.drop(['Adj Close 1 Day Future'],axis = 1)\n",
        "      df1['Adj Close 1 Day Future'] = target\n",
        "      df2 = df1.dropna()\n",
        "\n",
        "      # Rounded value of 20% of length of df2 for splitting\n",
        "      sp = round(test_ratio * len(df2))\n",
        "      train = df2[:-sp]\n",
        "      test = df2[-sp:]\n",
        "      train_X = train.iloc[:,0:-1]\n",
        "      train_y = train.iloc[:,-1]\n",
        "      test_X = test.iloc[:,0:-1]\n",
        "      test_y = test.iloc[:,-1]\n",
        "      regressor = AdaBoostRegressor()\n",
        "\n",
        "      regressor.fit(train_X,train_y)\n",
        "      from sklearn.metrics import mean_squared_error\n",
        "      predict_Y = regressor.predict(test_X)\n",
        "      r2 = regressor.score(test_X,test_y)\n",
        "      error = mean_squared_error(test_y,predict_Y)\n",
        "\n",
        "      RMSE = np.sqrt(error)\n",
        "      df_results = pd.DataFrame({'Predicted': predict_Y, 'Actual': test_y, 'Accuracy':100*(predict_Y)/test_y })\n",
        "      df_results.sort_values(by='Actual',axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
        "      import plotly.express as px\n",
        "      import plotly.graph_objects as go\n",
        "      # Create traces\n",
        "      fig3 = go.Figure()\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Actual\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Actual'))\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Predicted\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Predicted'))\n",
        "      fig3.layout.update(title_text = 'Prediction on Test data ' + selected_stock.split('.')[0] , \n",
        "                  xaxis_rangeslider_visible = True, width=900, height=600, \n",
        "                  yaxis_title='Closed Price : ' + selected_stock.split('.')[0],\n",
        "                  xaxis_title='Timeline')\n",
        "      #fig3.show()\n",
        "      return (regressor, fig1, fig2, fig3,r2 ,RMSE, df_results)\n",
        "      \n",
        "    # Function 10 - Support Vector Regressor - 1 day into the future\n",
        "    \n",
        "    def Support_Vector_Regressor(df_1):\n",
        "      from sklearn.svm import SVR\n",
        "      import plotly.graph_objects as go\n",
        "      df = df_1.copy(deep=True)\n",
        "      df['Date'] = df.index\n",
        "\n",
        "      #Sequential Split for Train and Test Data : Give it inside every UDF.\n",
        "      test_ratio = st.sidebar.slider(\"Test Ratio : for Sequential Split:\", 0.1, 0.9)\n",
        "      test_size = round(test_ratio * len(df))\n",
        "      st.write('Test Size :' ,test_size)\n",
        "      st.write('Train Size :' ,len(df) - test_size)\n",
        "\n",
        "      # Create traces\n",
        "      fig1 = go.Figure(layout = layout)\n",
        "      fig1.add_trace(go.Scatter(y=df[\"Close\"], x=df.Date,mode='lines',name='Closed price History' ))\n",
        "      fig1.layout.update(title_text = 'Closed price History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock : ' + selected_stock.split('.')[0] + ' :Close Price(INR)',\n",
        "                       xaxis_title='Timeline')\n",
        "      # Create traces\n",
        "      fig2 = go.Figure(layout = layout)\n",
        "      fig2.add_trace(go.Scatter(y=df[\"Volume\"], x=df.Date,\n",
        "                              mode='lines',name='Stock Purchased Voume' ))\n",
        "      fig2.layout.update(title_text = 'Stock Volume traded History : ' + selected_stock.split('.')[0] , \n",
        "                       xaxis_rangeslider_visible = True, \n",
        "                       yaxis_title='Stock Volume : ' + selected_stock.split('.')[0], xaxis_title='Timeline')\n",
        "\n",
        "    \n",
        "    \n",
        "      df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
        "      df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
        "      df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
        "\n",
        "      #Will predict this with a day ago value of Adj Close\n",
        "      df['Adj Close 1 Day Future'] = df['Adj Close'].shift(1)\n",
        "      df.drop(['Open','High','Low','Close'],inplace = True,axis = 1)\n",
        "\n",
        "      df=  df.dropna()\n",
        "      target = df['Adj Close 1 Day Future']\n",
        "      df1 = df.drop(['Date'],axis=1)\n",
        "      df1.drop(['Adj Close 1 Day Future'],axis = 1)\n",
        "      df1['Adj Close 1 Day Future'] = target\n",
        "      df2 = df1.dropna()\n",
        "\n",
        "      # Rounded value of 20% of length of df2 for splitting\n",
        "      sp = round(test_ratio * len(df2))\n",
        "      train = df2[:-sp]\n",
        "      test = df2[-sp:]\n",
        "      train_X = train.iloc[:,0:-1]\n",
        "      train_y = train.iloc[:,-1]\n",
        "      test_X = test.iloc[:,0:-1]\n",
        "      test_y = test.iloc[:,-1]\n",
        "      #Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n",
        "      #kernel = st.sidebar.selectbox(\"Enter Kernel Type : \",('linear', 'poly', 'rbf','sigmoid')) #Makes App Slow\n",
        "      regressor = SVR()\n",
        "\n",
        "      regressor.fit(train_X,train_y)\n",
        "      from sklearn.metrics import mean_squared_error\n",
        "      predict_Y = regressor.predict(test_X)\n",
        "      r2 = regressor.score(test_X,test_y)\n",
        "      error = mean_squared_error(test_y,predict_Y)\n",
        "\n",
        "      RMSE = np.sqrt(error)\n",
        "      df_results = pd.DataFrame({'Predicted': predict_Y, 'Actual': test_y, 'Accuracy':100*(predict_Y)/test_y })\n",
        "      df_results.sort_values(by='Actual',axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
        "      import plotly.express as px\n",
        "      import plotly.graph_objects as go\n",
        "      # Create traces\n",
        "      fig3 = go.Figure()\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Actual\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Actual'))\n",
        "      fig3.add_trace(go.Scatter(y=df_results[\"Predicted\"], x=df[-sp:].Date,\n",
        "                    mode='lines',\n",
        "                    name='Predicted'))\n",
        "      fig3.layout.update(title_text = 'Prediction on Test data ' + selected_stock.split('.')[0] , \n",
        "                  xaxis_rangeslider_visible = True, width=900, height=600, \n",
        "                  yaxis_title='Closed Price : ' + selected_stock.split('.')[0],\n",
        "                  xaxis_title='Timeline')\n",
        "      #fig3.show()\n",
        "      return (regressor, fig1, fig2, fig3,r2 ,RMSE, df_results)\n",
        "      \n",
        "    models_regression = (\"None\", \"Bayesian Ridge\",\"Orthogonal Matching Pursuit\",\n",
        "                       \"Multi Variate Regression\", \"Ridge Regression\", \"Random Forest Regressor\",\n",
        "                       \"Gradient Boosted Regressor\",\"Extra Trees Regressor\", \"AdaBoost Regressor\", \"Support Vector Regressor (needs Optimization)\", \"AR\", \"MA\", \"ARIMA\",\n",
        "                       \"VAR\", \"Convolutional Neural Networks\", \n",
        "                       \"RNN - LSTM\", \"FB-Prophet\")\n",
        "    \n",
        "    st.subheader('Model Selection - Stock : ' + selected_stock.split('.')[0])\n",
        "\n",
        "    regression_type = st.sidebar.selectbox(\"Select Chart type to visualize in the period\",models_regression)\n",
        "    st.spinner()\n",
        "    with st.spinner():\n",
        "      time.sleep(1)\n",
        "      #st.success('Done!')\n",
        "      \n",
        "    if regression_type == \"Multi Variate Regression\":\n",
        "      st.text(\"Running MSE\")\n",
        "      regressor, fig1, fig2, fig3, r2 ,RMSE, Intercept, Slope, df_results = Multi_Variate_Regression(data)\n",
        "      st.plotly_chart(fig1)\n",
        "      st.plotly_chart(fig2)\n",
        "      st.plotly_chart(fig3)\n",
        "      st.subheader(\"Regression Results\")\n",
        "      st.write(regressor)\n",
        "      st.write(f\"R-Squared value : {r2}\")\n",
        "      st.write(f\"Roost-Mean-Squared-Error : {RMSE}\")\n",
        "      st.write(f\"Intercept : {Intercept}\")\n",
        "      st.write(f\"Slope : {Slope}\")\n",
        "      df_results\n",
        "        \n",
        "    elif regression_type == \"Bayesian Ridge\":\n",
        "      st.text(\"Running Bayesian Ridge\")\n",
        "      regressor, fig1, fig2, fig3, r2 ,RMSE, Intercept, Slope, df_results = Bayesian_Ridge(data)\n",
        "      st.plotly_chart(fig1)\n",
        "      st.plotly_chart(fig2)\n",
        "      st.plotly_chart(fig3)\n",
        "      st.subheader(\"Regression Results\")\n",
        "      st.write(regressor)\n",
        "      st.write(f\"R-Squared value : {r2}\")\n",
        "      st.write(f\"Roost-Mean-Squared-Error : {RMSE}\")\n",
        "      st.write(f\"Intercept : {Intercept}\")\n",
        "      st.write(f\"Slope : {Slope}\")\n",
        "      df_results\n",
        "        \n",
        "    elif regression_type == \"Orthogonal Matching Pursuit\":\n",
        "      st.text(\"Running Prthogonal Matching Pursuit\")\n",
        "      regressor, fig1, fig2, fig3, r2 ,RMSE, Intercept, Slope, df_results = Orthogonal_Matching_Pursuit(data)\n",
        "      st.plotly_chart(fig1)\n",
        "      st.plotly_chart(fig2)\n",
        "      st.plotly_chart(fig3)\n",
        "      st.subheader(\"Regression Results\")\n",
        "      st.write(regressor)\n",
        "      st.write(f\"R-Squared value : {r2}\")\n",
        "      st.write(f\"Roost-Mean-Squared-Error : {RMSE}\")\n",
        "      st.write(f\"Intercept : {Intercept}\")\n",
        "      st.write(f\"Slope : {Slope}\")\n",
        "      df_results\n",
        "        \n",
        "    elif regression_type == \"Ridge Regression\":\n",
        "      st.text(\"Ridge Regression\")\n",
        "      regressor, fig1, fig2, fig3, r2 ,RMSE, Intercept, Slope, df_results = Ridge(data)\n",
        "      st.plotly_chart(fig1)\n",
        "      st.plotly_chart(fig2)\n",
        "      st.plotly_chart(fig3)\n",
        "      st.subheader(\"Regression Results\")\n",
        "      st.write(regressor)\n",
        "      st.write(f\"R-Squared value : {r2}\")\n",
        "      st.write(f\"Roost-Mean-Squared-Error : {RMSE}\")\n",
        "      st.write(f\"Intercept : {Intercept}\")\n",
        "      st.write(f\"Slope : {Slope}\")\n",
        "      df_results\n",
        "  \n",
        "    elif regression_type == \"FB-Prophet\":\n",
        "      st.text(\"Running FB-Prophet\")\n",
        "      forecast, fig1, fig2 = Prophet_model()\n",
        "      if fig2 == -1:\n",
        "          #forecast\n",
        "        st.plotly_chart(fig1)\n",
        "      else:\n",
        "        #forecast\n",
        "        st.plotly_chart(fig1)\n",
        "        st.plotly_chart(fig2)\n",
        "  \n",
        "    elif regression_type == \"AR\":\n",
        "      st.text(\"Running AR\")\n",
        "        \n",
        "    elif regression_type == \"MAA\":\n",
        "      st.text(\"Running MA\")\n",
        "        \n",
        "    elif regression_type == \"ARIMA\":\n",
        "      st.text(\"Running ARIMA\")\n",
        "\n",
        "    elif regression_type == \"AdaBoost Regressor\":\n",
        "      st.text(\"Running Adaboost Regressor\")\n",
        "      regressor, fig1, fig2, fig3, r2 ,RMSE, df_results = AdaBoost_Regressor(data)\n",
        "      st.plotly_chart(fig1)\n",
        "      st.plotly_chart(fig2)\n",
        "      st.plotly_chart(fig3)\n",
        "      st.subheader(\"Regression Results\")\n",
        "      st.write(regressor)\n",
        "      st.write(f\"R-Squared value : {r2}\")\n",
        "      st.write(f\"Roost-Mean-Squared-Error : {RMSE}\")\n",
        "      df_results\n",
        "  \n",
        "    elif regression_type == \"Extra Trees Regressor\":\n",
        "      st.text(\"Running Extra Trees Regressor\")\n",
        "      regressor, fig1, fig2, fig3, r2 ,RMSE, df_results = Extra_Trees_Regressor(data)\n",
        "      st.plotly_chart(fig1)\n",
        "      st.plotly_chart(fig2)\n",
        "      st.plotly_chart(fig3)\n",
        "      st.subheader(\"Regression Results\")\n",
        "      st.write(regressor)\n",
        "      st.write(f\"R-Squared value : {r2}\")\n",
        "      st.write(f\"Roost-Mean-Squared-Error : {RMSE}\")\n",
        "      df_results\n",
        "        \n",
        "    elif regression_type == \"Gradient Boosted Regressor\":\n",
        "      st.text(\"Running XGBoost\")\n",
        "      regressor, fig1, fig2, fig3, r2 ,RMSE, df_results = XgBoost_Regressor(data)\n",
        "      st.plotly_chart(fig1)\n",
        "      st.plotly_chart(fig2)\n",
        "      st.plotly_chart(fig3)\n",
        "      st.subheader(\"Regression Results\")\n",
        "      st.write(regressor)\n",
        "      st.write(f\"R-Squared value : {r2}\")\n",
        "      st.write(f\"Roost-Mean-Squared-Error : {RMSE}\")\n",
        "      df_results\n",
        "        \n",
        "    elif regression_type == \"VAR\":\n",
        "      st.text(\"Running VAR\")\n",
        "        \n",
        "    elif regression_type == \"Random Forest Regressor\":\n",
        "      st.text(\"Running Random Forest Regressor\")\n",
        "      regressor, fig1, fig2, fig3, r2 ,RMSE, df_results = Random_Forest(data)\n",
        "      st.plotly_chart(fig1)\n",
        "      st.plotly_chart(fig2)\n",
        "      st.plotly_chart(fig3)\n",
        "      st.subheader(\"Regression Results\")\n",
        "      st.write(regressor)\n",
        "      st.write(f\"R-Squared value : {r2}\")\n",
        "      st.write(f\"Roost-Mean-Squared-Error : {RMSE}\")\n",
        "      df_results\n",
        "        \n",
        "    elif regression_type == \"Support Vector Regressor (needs Optimization)\":\n",
        "      st.text(\"Running Support Vector Regressor\")\n",
        "      regressor, fig1, fig2, fig3, r2 ,RMSE, df_results = Support_Vector_Regressor(data)\n",
        "      st.plotly_chart(fig1)\n",
        "      st.plotly_chart(fig2)\n",
        "      st.plotly_chart(fig3)\n",
        "      st.subheader(\"Regression Results\")\n",
        "      st.write(regressor)\n",
        "      st.write(f\"R-Squared value : {r2}\")\n",
        "      st.write(f\"Roost-Mean-Squared-Error : {RMSE}\")\n",
        "      df_results\n",
        "        \n",
        "    elif regression_type == \"Convolutional Neural Networks\":\n",
        "      st.text(\"Running Convolutional Neural Networks\")\n",
        "\n",
        "    elif regression_type == \"RNN - LSTM\":\n",
        "      st.text(\"Running RNN - LSTM\")\n",
        "  \n",
        "    else:\n",
        "      st.text(\"Select suitable Statistical or Machine Learning Model from the above dropdown.\")\n",
        "\n",
        "  elif page == 'Algorithmic Trading':\n",
        "    st.subheader('Algo Trading Strategy - Stock : ' + selected_stock.split('.')[0])\n",
        "\n",
        "    algo_trading_strategy = (\"None\", \"RSI\", \"MFI\", \"Bollinger Bands\", \"MACD\", \"DEMA\", \"3-Moving Average\", \"OBV\")\n",
        "  \n",
        "    algo_trading_type = st.selectbox(\"Select your Algo-trading strategy\",algo_trading_strategy)\n",
        "    st.spinner()\n",
        "    with st.spinner():\n",
        "      time.sleep(1)\n",
        "    #st.success('Done!')\n",
        "\n",
        "    if algo_trading_type == \"RSI\":\n",
        "      st.text(\"Running RSI\")\n",
        "        \n",
        "    elif algo_trading_type == \"MFI\":\n",
        "      st.text(\"Running MFI\")\n",
        "  \n",
        "    elif algo_trading_type == \"Bollinger Bands\":\n",
        "      st.text(\"Running Bollinger Bands\")\n",
        "\n",
        "    elif algo_trading_type == \"MACD\":\n",
        "      st.text(\"Running MACD\")\n",
        "\n",
        "    elif algo_trading_type == \"DEMA\":\n",
        "      st.text(\"Running DEMA\")\n",
        "  \n",
        "    elif algo_trading_type == \"3-Moving Average\":\n",
        "      st.text(\"Running 3-Moving Average\")\n",
        "\n",
        "    elif algo_trading_type == \"OBV\":\n",
        "      st.text(\"Running OBV\")\n",
        "\n",
        "    else:\n",
        "      st.text('Select suitable Algo-Trading Strategy from the above dropdown.')\n",
        "\n",
        "  elif page == 'Portfolio Optimization':\n",
        "\n",
        "    #st.subheader('Optimization of Portfolio - Stock : ' + selected_stock.split('.')[0])\n",
        "    port_choice = st.selectbox(\"Do you want to Open Portfolio Optimization Module?\", ('No', 'Yes'))\n",
        "    if port_choice == 'Yes':\n",
        "      assets=[]\n",
        "      assets = st.multiselect('Select assets for your Portfolio : ', stocks)\n",
        "      col1, col2 = st.beta_columns(2)\n",
        "      col1.write(\"Select Start Date : \")\n",
        "      col2.write(\"Select End Date : \")\n",
        "      starting_date = col1.date_input(label = 'Start Date',value = dt.date(2019, 1, 1),min_value = dt.date(1992, 1, 1),max_value= date.today(), key = 123765)\n",
        "      ending_date = col2.date_input(label = 'End Date',min_value = dt.date(2000, 1, 1),max_value= date.today(), key = 154987)\n",
        "\n",
        "      col = st.selectbox(\"Select the price column based on which you want to analyse(Recommended Close or Adj Close)\", ['Open', 'High', 'Low', 'Close', 'Adj Close'])\n",
        "      data_portfolio = pd.DataFrame()\n",
        "      for stock in assets:\n",
        "        data_portfolio[stock] = web.DataReader(stock,data_source = 'yahoo', start= starting_date, end= ending_date )[col]\n",
        "\n",
        "      money = st.number_input('Enter money in (INR) you are willing to Invest : ')\n",
        "\n",
        "      def Portfolio_Optimization(stocks, money, data_portfolio):\n",
        "        from pypfopt.efficient_frontier import EfficientFrontier\n",
        "        from pypfopt import risk_models\n",
        "        from pypfopt import expected_returns\n",
        "        \n",
        "        df=data_portfolio.copy(deep = True)\n",
        "        # Visually show the Portfolio\n",
        "        import plotly.graph_objects as go\n",
        "        # we can show the adj close price history of all 5 stocks\n",
        "        from plotly.subplots import make_subplots\n",
        "        # Create traces height= 800, width = 1200,\n",
        "        if len(stocks) == 0:\n",
        "          stocks = []\n",
        "\n",
        "        # Assign Weights to stocks\n",
        "        if len(stocks)>=1 :\n",
        "          weights = np.ones(len(stocks)) * (1/len(stocks))\n",
        "        else:\n",
        "          weights = 0\n",
        "        \n",
        "        plot_list = []\n",
        "\n",
        "        for i in range(len(stocks)):\n",
        "        # create Traces\n",
        "          fig = go.Figure()\n",
        "          fig.add_trace(go.Scatter(x = df.index, y = df[stocks[i]],\n",
        "                          mode = 'lines', name = stocks[i].split('.')[0]))\n",
        "          # edit layout\n",
        "          fig.update_layout(title = stocks[i].split('.')[0] + ' : Adj Close Price History',\n",
        "                    xaxis_title = 'Timeline',\n",
        "                    yaxis_title = 'Adjusted Close Price(INR)',\n",
        "                    xaxis_rangeslider_visible = True, height = 400, width = 1200)\n",
        "          plot_list.append(fig)\n",
        "\n",
        "\n",
        "        #show the daily simple return\n",
        "        Returns = df.pct_change()\n",
        "        #Returns\n",
        "\n",
        "        # Create and show the annualized covarience matrix\n",
        "        cov_matrix_annual = Returns.cov()* 252\n",
        "        #cov_matrix_annual\n",
        "        # Calculate Portfolio Variance\n",
        "\n",
        "        try:\n",
        "          port_variance = np.dot(weights.T, np.dot(cov_matrix_annual, weights))\n",
        "        except AttributeError:\n",
        "          pass\n",
        "        \n",
        "        #port_variance\n",
        "        # Calculate Portfolio volatility / std. Dev.\n",
        "        port_volatility = np.sqrt(port_variance)\n",
        "        #port_volatility\n",
        "        # Calculate Portfolio Annual Return\n",
        "        Port_Anual_Return = np.sum(Returns.mean()*weights) * 252\n",
        "        #Port_Anual_Return\n",
        "        # Show the Return, Volatility(Risk) and Variance\n",
        "        percent_var = str(round(port_variance, 2)* 100) + '%'\n",
        "        percent_vol = str(round(port_volatility, 2)* 100) + '%'\n",
        "        percent_ret = str(round(Port_Anual_Return, 2)* 100) + '%'\n",
        "\n",
        "        #print(\"Annual Variance, Risk and Return Respectively\",percent_var,\",\", percent_vol, \",\", percent_ret)\n",
        "\n",
        "        # Start Portfolio optimisation\n",
        "        mu = expected_returns.mean_historical_return(df)\n",
        "        s = risk_models.sample_cov(df)\n",
        "        # Maximize The Sharpe Ratio\n",
        "        ef = EfficientFrontier(mu, s)\n",
        "        weights = ef.max_sharpe()\n",
        "        cleaned_weights = ef.clean_weights()\n",
        "        #print(\"Cleaned Weights\",cleaned_weights)\n",
        "        #ef.portfolio_performance(verbose= True)\n",
        "\n",
        "        # Discreet allocation of each share per stock\n",
        "        from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
        "\n",
        "        latest_prices = get_latest_prices(df)\n",
        "        weights = cleaned_weights\n",
        "        DA = DiscreteAllocation(weights,latest_prices, total_portfolio_value = money)\n",
        "\n",
        "        allocation, leftover = DA.lp_portfolio()\n",
        "        #print(\"Discreet Allocation:\", allocation)\n",
        "        #print(\"Funds Remaining: {:.2f}\".format(leftover))\n",
        "\n",
        "        return(plot_list,percent_var, percent_vol, percent_ret, cleaned_weights, allocation, leftover,ef.portfolio_performance(verbose= True),cov_matrix_annual)\n",
        "\n",
        "      plot_list, percent_var, percent_vol, percent_ret, cleaned_weights, allocation, leftover, portfolio_performance,cov_matrix_annual = Portfolio_Optimization(assets, money,data_portfolio)\n",
        "      st.subheader(\"Results of the Optimization : \")\n",
        "      st.write(f\"Portfolio : \")\n",
        "      for xxx in assets:\n",
        "        print(xxx.split(\".\")[0])\n",
        "\n",
        "      st.write(f'Proposed Investment : {money}')\n",
        "      st.write(\"Covariance Matrix Annual : \")\n",
        "      st.dataframe(cov_matrix_annual)\n",
        "      from collections import OrderedDict\n",
        "      df_cw = pd.DataFrame.from_dict(cleaned_weights, orient = 'index')\n",
        "      df_cw.reset_index(inplace=True)\n",
        "      df_cw_new = df_cw.rename(columns={0: 'Proportional contribution in Optimized Portfolio', 'index' : 'Assets'})\n",
        "      df_cw_new['% Contribution in Optimized Portfolio'] = round(df_cw_new['Proportional contribution in Optimized Portfolio'] *100,2)\n",
        "\n",
        "      st.write(f\"Cleaned Weights : \")\n",
        "      st.dataframe(df_cw_new)\n",
        "      st.write(f\"Portfolio Variance : {percent_var} \")\n",
        "      st.write(f\"Portfolio Volatility : {percent_vol}\")\n",
        "      st.write(f\"Portfolio Return : {percent_ret}\")\n",
        "      st.write(f\"Total Allocation : {allocation}\")\n",
        "      st.write(f\"Total Leftover : {leftover}\")\n",
        "      st.write(f\"Portfolio Performance : {portfolio_performance}\")\n",
        "\n",
        "    else:\n",
        "      st.write('Select Yes from the above box to open our Portfolio Optimization Module')\n",
        "\n",
        "  #if choice == 'Home':\n",
        "    #st.subheader(\"Streamlit From Colab\")\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing Stock_Market_Analysis_WebApp.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0S1lfxbaR3I",
        "outputId": "aa98653f-2a6b-40dd-bcdb-82ddbc2fe255"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  Stock_Market_Analysis_WebApp.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olNiLBfAbJO6",
        "outputId": "79ec9103-900f-45b6-ed54-bc81206f9a10"
      },
      "source": [
        "# Enter your ngrok authtoken here(XXXXX....), uncomment and run it.\n",
        "!ngrok authtoken 1sd8BKaUJpGGpevNcgleazl7BtI_4XdqS47sVgmMRgucE42br"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rraZixFvbaA_",
        "outputId": "8f7e1080-305e-4a10-9e25-407f7e45a37b"
      },
      "source": [
        "!ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME:\n",
            "   ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "DESCRIPTION:\n",
            "    ngrok exposes local networked services behinds NATs and firewalls to the\n",
            "    public internet over a secure tunnel. Share local websites, build/test\n",
            "    webhook consumers and self-host personal services.\n",
            "    Detailed help for each command is available with 'ngrok help <command>'.\n",
            "    Open http://localhost:4040 for ngrok's web interface to inspect traffic.\n",
            "\n",
            "EXAMPLES:\n",
            "    ngrok http 80                    # secure public URL for port 80 web server\n",
            "    ngrok http -subdomain=baz 8080   # port 8080 available at baz.ngrok.io\n",
            "    ngrok http foo.dev:80            # tunnel to host:port instead of localhost\n",
            "    ngrok http https://localhost     # expose a local https server\n",
            "    ngrok tcp 22                     # tunnel arbitrary TCP traffic to port 22\n",
            "    ngrok tls -hostname=foo.com 443  # TLS traffic for foo.com to port 443\n",
            "    ngrok start foo bar baz          # start tunnels from the configuration file\n",
            "\n",
            "VERSION:\n",
            "   2.3.40\n",
            "\n",
            "AUTHOR:\n",
            "  inconshreveable - <alan@ngrok.com>\n",
            "\n",
            "COMMANDS:\n",
            "   authtoken\tsave authtoken to configuration file\n",
            "   credits\tprints author and licensing information\n",
            "   http\t\tstart an HTTP tunnel\n",
            "   start\tstart tunnels by name from the configuration file\n",
            "   tcp\t\tstart a TCP tunnel\n",
            "   tls\t\tstart a TLS tunnel\n",
            "   update\tupdate ngrok to the latest version\n",
            "   version\tprint the version string\n",
            "   help\t\tShows a list of commands or help for one command\n",
            "\n",
            "PYNGROK VERSION:\n",
            "   4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD_ddZMBc2Uk"
      },
      "source": [
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4SWLoGSc2GU"
      },
      "source": [
        "!streamlit run Stock_Market_Analysis_WebApp.py &>/dev/null&"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm7DGZe4dB_X",
        "outputId": "ba804214-a189-47d3-bab5-0bd254256d44"
      },
      "source": [
        "#Gives you the Port number\n",
        "!pgrep streamlit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "CUXwktrebdYO",
        "outputId": "ab762bb5-5047-44ea-90c6-168468f08c16"
      },
      "source": [
        "# Setup a tunnel to the streamlit port 8501\n",
        "# Returns Public URL\n",
        "\n",
        "public_url = ngrok.connect(port='8501')\n",
        "public_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'http://fcf01d54470e.ngrok.io'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qv_sqD4btjK"
      },
      "source": [
        "!pgrep streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BxVunT0cBra"
      },
      "source": [
        "!kill 503"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OMiALPRcFDi"
      },
      "source": [
        "ngrok.kill()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}